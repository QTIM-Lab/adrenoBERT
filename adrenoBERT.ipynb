{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVawk6uwoBLk"
      },
      "source": [
        "#set the variable below\n",
        "multiclass_classification = True\n",
        "\n",
        "if not multiclass_classification:\n",
        "  num_classes = 2\n",
        "  fold_index = 0\n",
        "  experiment_name = \"adrenal_NLP_biobert_binary_reps_UMAP\"\n",
        "  k_folds = 5\n",
        "  experiment_name = experiment_name + str(fold_index)\n",
        "  print(experiment_name)\n",
        "  saved_weights_path = 'source_folder/' + 'saved_weights_' + experiment_name + '.pt'\n",
        "  \n",
        "else:\n",
        "  num_classes = 6\n",
        "  fold_index = 0\n",
        "  k_folds = 5\n",
        "\n",
        "  experiment_name = \"adrenal_NLP_biobert_multiclass_new_\"\n",
        "  experiment_name = experiment_name + str(fold_index)\n",
        "  saved_weights_path = 'source_folder/' + 'saved_weights_'  + experiment_name + '.pt'\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhVvIF-cnZfY"
      },
      "source": [
        "!git clone https://github.com/hila-chefer/Transformer-Explainability.git\n",
        "\n",
        "import os\n",
        "os.chdir(f'./Transformer-Explainability')\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install captum\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "UjMwlTClbDDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aLzIet44dLa"
      },
      "source": [
        "#for binary classification\n",
        "if not(multiclass_classification):\n",
        "  # Load the dataset into a pandas dataframe.\n",
        "  df = pd.read_csv(\"binary_data.csv\")\n",
        "  df['sentence'] = df['text']\n",
        "  df = df[['sentence', 'label']]\n",
        "\n",
        "  #check for and drop empty sentences\n",
        "  print(df.isna().any())\n",
        "  df = df.dropna(how='any', subset = ['sentence'])\n",
        "  print(df['label'].unique())\n",
        "  # Report the number of sentences.\n",
        "  print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "  # Display 10 random rows from the data.\n",
        "  print(df.sample(10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a1anD4cmBk6"
      },
      "source": [
        "#for multiclass classification\n",
        "if multiclass_classification:\n",
        "  df = pd.read_csv(\"multiclass_data.csv\")\n",
        "  print(df.head())\n",
        "  \n",
        "  train_df = df[['sample_text', 'sample_label']]\n",
        "  print(len(train_df))\n",
        "  \n",
        "  print(train_df['sample_label'].unique())\n",
        "  print(train_df['sample_label'].value_counts())\n",
        "\n",
        "  text_list = list(train_df['sample_text'])\n",
        "  label_list = list(train_df['sample_label'])\n",
        "\n",
        "  #convert labels to one-hot encoding\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(label_list)\n",
        "  labels = le.transform(train_df['sample_label'])#.astype('category'))\n",
        "  \n",
        "  new_df = pd.DataFrame()\n",
        "  new_df['sentence'] = text_list\n",
        "  new_df['label'] = labels\n",
        "  \n",
        "  df = new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1mTnlAY58M_"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                    \n",
        "                        add_special_tokens = True\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "source": [
        "#pad tokens\n",
        "MAX_LEN = 128\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "##Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8g2arDqaAAG"
      },
      "source": [
        "#5-fold cross-validation\n",
        "test_size_fraction = 0.10\n",
        "\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=test_size_fraction, stratify=labels)\n",
        "\n",
        "\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=test_size_fraction)\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=2018)\n",
        "skf.get_n_splits(input_ids, labels)\n",
        "\n",
        "print(skf)\n",
        "\n",
        "folds = {}\n",
        "X = input_ids\n",
        "y = labels\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(train_inputs, train_labels)):\n",
        "    folds[i] = (train_index, valid_index)\n",
        "\n",
        "\n",
        "train_index = folds[fold_index][0]\n",
        "valid_index = folds[fold_index][1]\n",
        "print(fold_index)\n",
        "\n",
        "\n",
        "def get_attn_masks(attention_masks, index_list):\n",
        "  return [attention_masks[idx] for idx in index_list]\n",
        "\n",
        "train_inputs, train_masks, train_labels = input_ids[train_index], get_attn_masks(attention_masks, train_index), labels[train_index]\n",
        "validation_inputs, validation_masks, validation_labels = input_ids[valid_index], get_attn_masks(attention_masks, valid_index), labels[valid_index]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "source": [
        "# Convert to tensors\n",
        "import torch \n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "train_batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=train_batch_size)\n",
        "\n",
        "test_batch_size = 16\n",
        "#Create a loader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\", \n",
        "    num_labels = num_classes, \n",
        "    output_attentions = True, \n",
        "    output_hidden_states = True \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "if not multiclass_classification:\n",
        "  epochs = 4\n",
        "else:\n",
        "  epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "print(total_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "import random\n",
        "\n",
        "# training code based on https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "train_loss_values = []\n",
        "valid_loss_values = []\n",
        "\n",
        "valid_accuracy_values = []\n",
        "max_valid_accuracy = -1\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        \n",
        "        batch = [r.cuda() for r in batch]\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        model.zero_grad()        \n",
        "        \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    train_loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "  \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    \n",
        "    for batch in validation_dataloader:\n",
        "    \n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():        \n",
        "          outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    valid_accuracy = eval_accuracy/nb_eval_steps\n",
        "    valid_accuracy_values.append(valid_accuracy)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.5f}\".format(valid_accuracy))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    if valid_accuracy > max_valid_accuracy:\n",
        "      torch.save(model.state_dict(), saved_weights_path)\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "plt.plot(train_loss_values, 'b-o')\n",
        "plt.title(experiment_name + \" - Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "out_dir = \"source_folder/plots/\"\n",
        "out_confus = out_dir + experiment_name + '_train_loss' + '.png'\n",
        "plt.savefig(out_confus, dpi=300,facecolor='w')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXP-v2agWJSJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "plt.plot(valid_accuracy_values, 'b-o')\n",
        "plt.title(experiment_name + \" - Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "out_confus = out_dir + experiment_name + '_valid_accuracy' + '.png'\n",
        "plt.savefig(out_confus, dpi=300,facecolor='w')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5457GPomgTG"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "#load best model to predict\n",
        "test_model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels = num_classes, output_hidden_states=True)\n",
        "test_model.load_state_dict(torch.load(saved_weights_path))#saved_weights_path))\n",
        "test_model.eval()\n",
        "test_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dump biobert embeddings to pickle file for visualisation\n",
        "\n",
        "text_list = [tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(i, skip_special_tokens=True)) for i in test_inputs]\n",
        "print(len(text_list))\n",
        "print(len(new_test_y))\n",
        "\n",
        "hover_data = pd.DataFrame({'index':np.arange(len(new_test_y)),'text': text_list,'label': le.inverse_transform(new_preds)})\n",
        "#saving the data in a pickle file to plot a umap\n",
        "import pickle\n",
        "\n",
        "s = {}\n",
        "\n",
        "s['representations']=reps #np_encoded_text\n",
        "s['labels']=new_preds\n",
        "s['hover_data']=hover_data\n",
        "\n",
        "outfile=open('adrenal_NLP_biobert_multiclass_trained_predictions.pkl', 'wb')\n",
        "\n",
        "pickle.dump(s, outfile)\n",
        "\n",
        "outfile.close()"
      ],
      "metadata": {
        "id": "ppxZ9XWDFFlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDELs0JLXx41"
      },
      "source": [
        "#test_accuracy\n",
        "t0 = time.time()\n",
        "eval_accuracy = 0\n",
        "nb_eval_steps = 0\n",
        "logits_stack = []\n",
        "labels_stack = []\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "        \n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():        \n",
        "    outputs = test_model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  logits_stack.append(logits)\n",
        "  labels_stack.append(label_ids)\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "#calculate test accuracy\n",
        "test_accuracy = eval_accuracy/nb_eval_steps\n",
        "print(\"  Accuracy: {0:.5f}\".format(test_accuracy))\n",
        "print(\"  Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syb0fF6IlpXy"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_preds = np.vstack(tuple(logits_stack))\n",
        "new_test_y = test_labels.detach().cpu()\n",
        "new_preds = np.argmax(test_preds, axis=1).flatten()\n",
        "\n",
        "print(classification_report(new_test_y, new_preds))\n",
        "# confusion matrix\n",
        "\n",
        "pd.crosstab(new_test_y, new_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxG1rO0BoGLL"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "\n",
        "out_dir = \"source_folder\"\n",
        "master_sheet = pd.DataFrame()\n",
        "master_sheet['label'] = new_test_y\n",
        "master_sheet['Prediction'] = new_preds\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69MFQziTom20"
      },
      "source": [
        "if not multiclass_classification:\n",
        "  y_true = master_sheet['label']\n",
        "  y_pred = master_sheet['Prediction']\n",
        "\n",
        "\n",
        "  conf = confusion_matrix(y_true, y_pred) \n",
        "  tick_labels = [\"Normal\", \"Abnormal\"]\n",
        "  df_cm = pd.DataFrame(conf, index=tick_labels, columns=tick_labels)\n",
        "  fig, ax = plt.subplots()\n",
        "  sns.heatmap(df_cm, cmap='Blues', annot=True, fmt='g', annot_kws={\"size\": 16})\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "  plt.xlabel('Automated diagnosis')\n",
        "  plt.ylabel('Reference standard diagnosis')\n",
        "  plt.title(experiment_name + \": Report level confusion matrix - (n = {})\".format(master_sheet.shape[0]))#master_sheet.shape[0]))\n",
        "  out_confus = out_dir + experiment_name + '_confusion_report_level' + '.png'\n",
        "  plt.savefig(out_confus, dpi=300,facecolor='w')\n",
        "  plt.show() \n",
        "\n",
        "else:\n",
        "  y_true = master_sheet['label']\n",
        "  y_pred = master_sheet['Prediction']\n",
        "\n",
        "\n",
        "  conf = confusion_matrix(y_true, y_pred) \n",
        "  tick_labels = le.inverse_transform([0, 1, 2, 3, 4, 5])\n",
        "  df_cm = pd.DataFrame(conf, index=tick_labels, columns=tick_labels)\n",
        "  fig, ax = plt.subplots()\n",
        "  sns.heatmap(df_cm, cmap='Blues', annot=True, fmt='g', annot_kws={\"size\": 18})\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "  plt.xlabel('Automated diagnosis')\n",
        "  plt.ylabel('Reference standard diagnosis')\n",
        "  plt.title(experiment_name + \": Report level confusion matrix - (n = {})\".format(master_sheet.shape[0]))#master_sheet.shape[0]))\n",
        "  out_confus = out_dir + experiment_name + '_confusion_report_level' + '.png'\n",
        "  plt.savefig(out_confus, dpi=300,facecolor='w')\n",
        "  plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2AGJ03aoqzd"
      },
      "source": [
        "#plot AUROC\n",
        "y_true = master_sheet['label']\n",
        "y_pred = master_sheet['Prediction']\n",
        "\n",
        "\n",
        "fpr_adrenal, tpr_adrenal, _ = roc_curve(y_true, y_pred)\n",
        "auc_adrenal = auc(fpr_adrenal, tpr_adrenal)\n",
        "plt.plot(fpr_adrenal, tpr_adrenal, lw=2, label='Abnormal vs. Normal (AUC = %0.2f)' % auc_adrenal)\n",
        "plt.legend()\n",
        "plt.ylabel('Sensitivity')\n",
        "plt.xlabel('1 - Specificity')\n",
        "plt.title(experiment_name + \": Analysis of Reports, per report (n = {})\".format(master_sheet.shape[0]))\n",
        "out_aucpi = out_dir + experiment_name + '_AUC_per_report' + '.png'\n",
        "plt.savefig(out_aucpi, dpi=300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opgr065Fouz-"
      },
      "source": [
        "#plot AUPRC\n",
        "y_true = master_sheet['label']\n",
        "y_pred = master_sheet['Prediction']\n",
        "\n",
        "\n",
        "precision_adrenal, recall_adrenal, _ = precision_recall_curve(y_true, y_pred)\n",
        "ap_adrenal = average_precision_score(y_true, y_pred)\n",
        "\n",
        "plt.plot(precision_adrenal, recall_adrenal, lw=2, label='Abnormal vs. Normal(Avg. Precision = %0.2f)' % ap_adrenal)\n",
        "plt.legend()\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Recall')\n",
        "plt.title(experiment_name + \": Analysis of Report data, per image (n = {})\".format(master_sheet.shape[0]))\n",
        "out_auprc = out_dir + experiment_name + '_PR_per_report' + '.png'\n",
        "plt.savefig(out_auprc, dpi=300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate CI by using the folds as the samples\n",
        "#for AUROC, AUPRC, Kappa, etc.\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "def mean_confidence_interval(data, confidence=0.95):\n",
        "    a = 1.0 * np.array(data)\n",
        "    n = len(a)\n",
        "    m, se = np.mean(a), scipy.stats.sem(a)\n",
        "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
        "    return m, m-h, m+h\n",
        "\n",
        "\n",
        "f1_scores = [0.56, 0.80, 0.52, 0.70, 0.54, 0.05]\n",
        "supports = [51, 796, 93, 444, 304, 17]\n",
        "\n",
        "sum_supports = sum(supports)\n",
        "kappa_value_array1 = [(i*j)/sum_supports for i, j in zip(f1_scores, supports)]\n",
        "print(\"weighted avg F1 = \", sum(kappa_value_array1))\n"
      ],
      "metadata": {
        "id": "2Zhid62WGIqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from math import sqrt\n",
        "\n",
        "def roc_auc_ci(y_true, y_score, positive=1):\n",
        "    AUC = roc_auc_score(y_true, y_score)\n",
        "    N1 = sum(y_true == positive)\n",
        "    N2 = sum(y_true != positive)\n",
        "    Q1 = AUC / (2 - AUC)\n",
        "    Q2 = 2*AUC**2 / (1 + AUC)\n",
        "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
        "    lower = AUC - 1.96*SE_AUC\n",
        "    upper = AUC + 1.96*SE_AUC\n",
        "    if lower < 0:\n",
        "        lower = 0\n",
        "    if upper > 1:\n",
        "        upper = 1\n",
        "    return (lower, upper)"
      ],
      "metadata": {
        "id": "BNaaFoWa9Rn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu67MbBYXlpC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import auc\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def roc_curve_and_score(y_test, pred_proba):\n",
        "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
        "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
        "    return fpr, tpr, roc_auc\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "matplotlib.rcParams.update({'font.size': 14})\n",
        "plt.grid()\n",
        "\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "colors = ['pink', 'green', 'red', 'blue', 'orange', 'cyan', 'purple', 'yellow']\n",
        "for i in range(5):\n",
        "  df = pd.read_csv('adrenal_binary_biobert_fold_' + str(i) + '.csv')\n",
        "  y_true = df['label']\n",
        "  y_pred = df['Prediction']\n",
        "  fpr, tpr, roc_auc = roc_curve_and_score(y_true, y_pred)\n",
        "  conf_inter = roc_auc_ci(y_true, y_pred)\n",
        "  plt.plot(fpr, tpr, color=colors[i], lw=2, label='ROC AUC={0:.3f} {z} (fold {x})'.format(roc_auc, z = conf_inter, x = i+1), alpha=0.7)\n",
        "  interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
        "  interp_tpr[0] = 0.0\n",
        "  tprs.append(interp_tpr)\n",
        "  aucs.append(roc_auc)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('1 - Specificity')\n",
        "plt.ylabel('Sensitivity')\n",
        "\n",
        "plt.title('Mean AUROC')\n",
        "out_auroc_cumul = out_dir + experiment_name + 'multiAUROC' + '.png'\n",
        "plt.savefig(out_auroc_cumul)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aOSbMySrYz-"
      },
      "source": [
        "#calculate kappa values  and mean average precision\n",
        "if multiclass_classification:\n",
        "  from sklearn.metrics import cohen_kappa_score # as cohen_kappa_score\n",
        "  kappa_unweighted = cohen_kappa_score(y_true, y_pred)#, weights=\"unweighted\")\n",
        "  kappa_linear = cohen_kappa_score(y_true, y_pred, weights=\"linear\")\n",
        "  kappa_quadratic = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
        "  print(kappa_unweighted, kappa_linear, kappa_quadratic)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regex for multiclass\n",
        "\n",
        "#mapping to encoder\n",
        "label_dict = {\n",
        "    'absent': 0, \\\n",
        "    'mass': 1, \\\n",
        "    'metastasis': 2, \\\n",
        "    'normal': 3, \\\n",
        "    'thickening': 4, \\\n",
        "    'unknown': 5\n",
        "}\n",
        "\n",
        "phrases_dict = {\n",
        "    'absent': ['absent'], \\\n",
        "    'mass': ['mass', 'nodule'], \\\n",
        "    'metastasis': ['metastasis'], \\\n",
        "    'normal': ['normal'], \\\n",
        "    'thickening': ['thickening'], \\\n",
        "    'unknown': ['unknown']\n",
        "}\n",
        "\n",
        "#decreasing order of criticality\n",
        "priority = ['mass', 'metastasis', 'thickening', 'absent', 'normal', 'unknown']\n",
        "\n",
        "#to store predictions\n",
        "predictions = []\n",
        "\n",
        "#loop to detect mention and assign label\n",
        "\n",
        "for s in sentences:\n",
        "  l = 5\n",
        "  for p in priority:\n",
        "    if any([1 if w in s else 0 for w in phrases_dict[p]]):\n",
        "      l = label_dict[p]\n",
        "      break;\n",
        "  \n",
        "  #if l == '-111':\n",
        "  #  print(s)\n",
        "  predictions.append(l)\n",
        "\n",
        "print(predictions[:10])\n",
        "predictions.count(5)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels, predictions))"
      ],
      "metadata": {
        "id": "-XV4Sj_Ztp54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z9inFnDGj81"
      },
      "source": [
        "#Feature Extraction for UMAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NOqXsz2GjQ-"
      },
      "source": [
        "model_feature_extraction = BertForSequenceClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = num_classes, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQyomDUMwcS"
      },
      "source": [
        "model_feature_extraction.load_state_dict(torch.load(saved_weights_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyZn3SjHGvPE"
      },
      "source": [
        "#Transformer Explainability\n",
        "\n",
        "###Code based on https://github.com/hila-chefer/Transformer-Explainability.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUjXpkL1esbA"
      },
      "source": [
        "os.chdir(f'/content/Transformer-Explainability')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtmU21nAe-7u"
      },
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from BERT_explainability.modules.BERT.ExplanationGenerator import Generator\n",
        "from BERT_explainability.modules.BERT.BertForSequenceClassification import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from BERT_explainability.modules.BERT.ExplanationGenerator import Generator\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import matplotlib\n",
        "print(matplotlib.__version__)\n",
        "from captum.attr import (\n",
        "    visualization\n",
        ")\n",
        "import torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQTA15i2Dqn"
      },
      "source": [
        "#load biobert model\n",
        "vis_model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels = num_classes)\n",
        "saved_weights_path = \"saved_weights_adrenal_multiclass_biobert_fold_2.pt\"\n",
        "vis_model.load_state_dict(torch.load(\"/content/drive/My Drive/Fracture/\" + saved_weights_path))\n",
        "vis_model.eval()\n",
        "vis_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9yyUNHdpl3S"
      },
      "source": [
        "# initialize the explanations generator\n",
        "explanations = Generator(vis_model)\n",
        "\n",
        "if multiclass_classification:\n",
        "  classifications = le.inverse_transform([i for i in range(num_classes)])\n",
        "else:\n",
        "  classifications = [\"NEGATIVE\", \"POSITIVE\"]\n",
        "print(classifications)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVZ-cRLS1Vsn"
      },
      "source": [
        "visualisations = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZnZaQTwKxAE"
      },
      "source": [
        "def simpler_format(tokens, expl):\n",
        "  #trying to merge weights for split tokens\n",
        "  tokens2 = tokenizer.convert_tokens_to_string(tokens).split(' ')\n",
        "  \n",
        "  expl2 = expl\n",
        "\n",
        "  for i in range(len(tokens)-1, -1, -1):\n",
        "    if tokens[i].startswith('##'):\n",
        "      expl2[i-1] = max(expl2[i], expl2[i-1])\n",
        "\n",
        "  expl2 = [expl2[i] for i in range(len(expl2)) if not tokens[i].startswith('##')]\n",
        "  expl2 = expl2[1:-1]\n",
        "  tokens2 = tokens2[1:-1]\n",
        "  assert len(tokens2) == len(expl2)\n",
        "  return tokens2, expl2\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHM3AVfWz0db"
      },
      "source": [
        "test_sents = [tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(token_ids.numpy())) for token_ids in test_inputs]\n",
        "print(len(test_sents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ0I4Lm0pmDi",
        "collapsed": true
      },
      "source": [
        "     \n",
        "visualisations = []\n",
        "preds_vis_model = []\n",
        "l = 0\n",
        "sents = test_sents[l:l+10]\n",
        "\n",
        "for i in range(len(test_sents)):\n",
        "  text_batch = test_sents[i]             \n",
        "  encoding = tokenizer(text_batch, return_tensors='pt')\n",
        "  input_ids = encoding['input_ids'].to(\"cuda\")\n",
        "  attention_mask = encoding['attention_mask'].to(\"cuda\")\n",
        "\n",
        "  # true class is positive - 1\n",
        "  true_class = test_labels[i]\n",
        "\n",
        "  # generate an explanation for the input\n",
        "  expl = explanations.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, start_layer=0)[0]\n",
        "  # normalize scores\n",
        "  expl = (expl - expl.min()) / (expl.max() - expl.min())\n",
        "\n",
        "  # get the model classification\n",
        "  output = torch.nn.functional.softmax(vis_model(input_ids=input_ids, attention_mask=attention_mask)[0], dim=-1)\n",
        "  classification = output.argmax(dim=-1).item()\n",
        "  # get class name\n",
        "  class_name = classifications[classification]\n",
        "\n",
        "  preds_vis_model.append(classification)\n",
        "\n",
        "   \n",
        "  # if the classification is negative, higher exp lanation scores are more negative\n",
        "  # flip for visualization\n",
        "  #if class_name == \"NEGATIVE\":\n",
        "  if class_name == \"POSITIVE\":\n",
        "    expl *= (-1)\n",
        "\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  print([(tokens[i], expl[i].item()) for i in range(len(tokens))])\n",
        "  tokens2, expl2 = simpler_format(tokens, expl)\n",
        "\n",
        "  vis_data_records = [visualization.VisualizationDataRecord(\n",
        "                                  expl2,\n",
        "                                  output[0][classification],\n",
        "                                  classification,\n",
        "                                  true_class,\n",
        "                                  1,\n",
        "                                  1,       \n",
        "                                  tokens2,\n",
        "                                  1)]\n",
        "  visualization.visualize_text(vis_data_records)\n",
        "  visualisations.append(visualization.visualize_text(vis_data_records))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, Image\n",
        "i = 73\n",
        "filename = \"0_2___\" + str(i)\n",
        "v = visualisations[i]\n",
        "display(HTML(v.data))\n",
        "with open(filename + '.html', 'w') as f:\n",
        "  f.write(v.data)"
      ],
      "metadata": {
        "id": "lQmvaEIE09ZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}